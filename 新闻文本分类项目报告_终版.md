# 新闻文本分类项目报告

## 1. 数据获取及预处理

### 1.1 数据来源

近年来，随着人工智能的发展，其在语音识别、自然语言处理、图像与视频分析等诸多领域取得了巨大成功。本次项目将聚焦在新闻文本的分类，利用人工智能技术，对新闻文本进行分类。要求给出一个算法或模型，对于给定的文本，检测出文本所属类别。

从天池官网下载到完整的新闻数据集，地址为[天池-新闻文本分类 ](https://tianchi.aliyun.com/competition/entrance/531810/introduction)

### 1.2 数据说明

**（1）数据集分为1个训练集和测试集A**,**B**

- 训练集含数据样本**20万条**
- 测试集A含数据样本**5万条**
- 测试集B是网站用于对提交模型的精度进行评估的，不支持下载

**（2）训练集原始字段为label（新闻类别），text（匿名处理后的新闻文本）**
![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220413143233284.png)

**（3）测试集A仅包含text（匿名处理后的新闻文本）字段**

![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414143340846.png)

### 1.3 数据预处理

**（1）查看数据缺失情况和重复情况**

- 无缺失值，无需处理
- 需处理重复数据

![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414142809426.png)

**（2）数据去重**

![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414143229737.png)

## 2. 数据分析与可视化

### 2.1查看新闻类别的柱状图和占比可知：

- 数量排名前4的科技、股票、体育、娱乐类占据了总体60%以上的新闻

- 数量倒数后5的游戏、房产、时尚、彩票、星座类合计占10%左右

- 整体类别分布不均匀
  ![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414145453509.png)
  ![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/%E4%B8%8B%E8%BD%BD.png)

### 2.2.查看新闻文本的字符长短情况：

- 由对新闻文本字符数目的五数概括描述可知：

  - 平均长度为907个字符

  - 最短2个字符

  - 25%在374个字符以内

  - 50%在647个字符以内

  - 75%在1131个字符以内

  - 最长57921个字符

  - 由新闻文本字符数目箱型图可观察到较多离群点，整体新闻文本字符数分布不太均匀，结合直方图可分析其绝大部分整体长度都在将近2000以下

  ![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414145357967.png)

  ![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414145528662.png)

### 2.3 查看所有新闻文本中出现频率最高的前20个字符：

- 出现频率最高的是字符‘3750’，748万次
- 排名前3字符之后基本都低于200万次

![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414153117048-16499230026174.png)

### 2.4 统计各字符在20万条新闻中的出现概率：

- 前3的字符“3750”，‘’900‘’，‘’648‘’的**在20万条新闻中每条出现概率超过95%**，猜测可能是标点符号(符合上条前三字符均超过200万次)
![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/image-20220414154545968-16499229916592.png)



## 3. 模型选取

### 3.1 TFIDF+SVM分类

#### 3.1.1 模型选取缘由 ：

词频-逆向文档频率( Term Frequency-Inverse Document Frequency,TFIDF ) 是一种基于统计的数学方法，其通过统计当前样本中每个词的 TFIDF 值作为特征向量的每个元素，从而可以判断出一个词语或短语在样本集中的重要程度。TFIDF 方法计算公式如下:

![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/master/gongshi.png)


由上述定义，FTFIDFi，j越大，则表示某词条 ni 对样本 j 越重要，TFIDF方法在文本特征提取上有广泛的应用，且在文本分类任务中效果显著，因此本项目用TFIDF提取文本特征。

支持向量机（Support Vector Machine，SVM）是作为是一类按监督学习方式对数据进行二元分类的线性分类器，它具有泛化错误率低、计算开销不大和结果易理解等特点，同时像本实验数据集样本总数（本实验20万样本）比文本特征词数量（本实验最大文本特征数量为1万）比较大时，更适合用基于线性核函数的SVM（或logistic回归）来完成分类任务，因此本项目用SVM线性分类器完成文本分类任务。

#### 3.1.2 实验步骤

- 首先，利用TFIDF提取文本词语的特征信息；
- 为了充分表征文本信息，我们也提取文本字的ngram信息，我们将ngram设置为（1，3），即最少提取单个词语作为文本特征，最多会提取3个词语作为文本特征词；
- 所有的文本特征都提取完成后，我们就可以用机器学习的分类器——支持向量机（SVM），训练模型。这是一个多标签问题，我们将其看作6个二分类问题求解，即我们假设两两标签是没有关系的。

#### 3.1.3 分类结果

由于天池新闻文本分类赛题提供的测试集A中仅包含需要预测的新闻文本，不包含其标签，因此我们无法对测试集的结果进行直观的分析。为了能对新闻文本分类结果做一个比较直观的分析，我们从赛题提供的训练集中抽取部分数据集作为线下实验的验证集，我们把训练数据集分成5个子数据集，通过K折交叉验证的方式进行试验，其中4个子数据集作为训练数据集，1个子数据集作为验证集，从而使训练集与验证集的比值达到8:2（16万：4万），实验结果为如下：

下面图中混淆矩阵及其他结果中的每一行从左到右（第0列到13列），从上到下（第0行到13行）分别代表：'科技'，'股票'，, '体育'， '娱乐'， '时政'， '社会'， '教育'， '财经'， '家居'， '游戏'，'房产'， '时尚'， '彩票'， '星座'等类别，其中混淆矩阵中行代表其真实类别，列代表其预测类别：

（1）第 1 折交叉验证的实验结果

​		混淆矩阵为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/matrix1.png" style="zoom:80%;" />

​		每一个新闻类别的precision、recall、f1-score以及总的accuracy为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/evaluation1.png" style="zoom:80%;" />

（2）第 2 折交叉验证的实验结果

​		混淆矩阵为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/matrix2.png" style="zoom:80%;" />

​		每一个新闻类别的precision、recall、f1-score以及总的accuracy为如下：

 <img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/evaluation2.png" style="zoom:80%;" />

​		（3）第 3折交叉验证的实验结果

​		混淆矩阵为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/matrix3.png" style="zoom:80%;" />

​		每一个新闻类别的precision、recall、f1-score以及总的accuracy为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/evaluation3.png" style="zoom:80%;" />

​		（4）第 4折交叉验证的实验结果

​		混淆矩阵为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/matrix4.png" style="zoom:80%;" />

​		每一个新闻类别的precision、recall、f1-score以及总的accuracy为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/evaluation4.png" style="zoom:80%;" />

​		（5）第 5折交叉验证的实验结果

​		混淆矩阵为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/matrix5.png" style="zoom:80%;" />

​		每一个新闻类别的precision、recall、f1-score以及总的accuracy为如下：

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/evaluation5.png" style="zoom:80%;" />

 

​		其中accuracy指标最高值为0.95，最低值为0.95；precision（macro）指标最高值为0.95最，低值为0.94；recall（macro）指标最高值为0.94，最低值为0.93；f1-score（macro）指标最高值为0.95，最低值为0.94。

#### 3.1.4 赛题官网在线分类结果

​		我们用赛题官网提供的20万训练集训练完我们的模型后对对赛题提供的大小为5万的测试集A进行了测试并提交结果到天池赛题官网，测试结果为如下（评价指标为F1值）：

​		<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/online_test_TFIDF.png" style="zoom:80%;" />

### 3.2 Bert+softmax

#### 3.2.1 模型选取理由

为了对新闻文本进行分类，我们也可以将句子进行编码，构建属于句子的表示，即词向量，随后通过softmax进行分类。

为了将句子编码成词向量，我们可以考虑许多模型，如word2vec等，但考虑到需要考虑整句的前后联系与上下文，采用BERT编码成上下文相关词向量会使得编码词向量的代表性更强。因此我们采用BERT编码文本，随后通过softmax进行多分类。

#### 3.2.2 实验步骤

（1）读取训练集。由于BERT的最大输入长度是512，而样本中最长的样本远超这个数字，因此我们需要对文本进行裁剪得到可以供BERT使用的数据集。本次实验取文本的头与尾的部分字符，加上拼接的token，长度为256。

（2）将得到数据集的输入BERT模型后，通过softmax进行训练与测试。

#### 3.2.3 赛题官网在线分类结果

分别在大小为20000的训练集和200000的训练集上分别进行了训练，并进行预测，最后的结果如下所示：

![](https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/online_test_bert.png)

上方为在全部训练集上进行训练的模型得到的结果，下方为在大小为20000的训练集上进行训练的模型得到的结果。

由此可见，该方法对于数据集的大小有一定的要求，数据集足够大能够得到很好的结果。

## 4. 挖掘实验分析

由于本次赛题提供的测试集A中只提供了新闻文本，没有提供其对应类别标签，因此我们无法对测试集A的结果做一个很直观的分析，为了能比较直观地分析，我们用TFIDF+SVM模型做K折交叉验证的实验结果做简要分析。从上一章的5次交叉验证的实验结果很接近，没有很大差别，所以我们选取第1折的实验结果对它进行分析。

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/Analysis_1.png" style="zoom:80%;" />

从第1折的混淆矩阵图中看到很类别被错误地预测成'科技'类（红色框线），同时'科技'类相对于其他类预测错误（蓝色框线）的数量也较多，我们认为出现这一情况的原因有

（i）’科技’类的新闻文本数量多且特征词更广泛且经典，因此某些跟’科技’类有类似特征项的被错误地预测；

（ii）’科技’ 类的新闻文本数目最多，因此个别文本没有科技类典型特征而错误地被预测 。

同时从混淆矩阵中看到’财经’被误预测成’体育’类的（橙色框线）相对很突出，我们认为这是因为通常报道财经相关的新闻或多或少很跟体育竞技相关，因此’财经’类中的部分文本跟体育相关而预测成’体育’类。

<img src="https://raw.githubusercontent.com/Eshjamtsand/DATA-MINING-HOMEWORK/main/test_resul_images/Analysis_2.png" style="zoom:80%;" />

​		我们从第1折的评估指标中看到，’体育’类新闻文本的分类结果最客观，而’财经’类别的新闻文本的分类结果相对来说较差，我们假设’体育’类别的特征项比较特有且经典，而’财经’类别设计的范围比较广，因此有了上述的实验结果。

​		总体来说，新闻文本分类结果较准确，F1值达到0.94, accuracy值为0.95, precision（macro）为0.94；recall（macro）值为0.93。

### 五.成员及分工

依西降参（3220211100）：TFIDF+SVM算法实现，及其结果分析；
吕星辰（3120215503）：数据分析与可视化；
穆育松（3220211058）：Bert+softmax算法实现；
金玉卿（3120215523 ）：资料整理与文档撰写。

